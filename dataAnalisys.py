import pandas as pd
import numpy as np
import pymongo
from nltk.sentiment import SentimentIntensityAnalyzer
from textblob import TextBlob
import io
import os
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from urllib.parse import quote_plus
from datetime import datetime
import traceback
import json


class MindCheckAnalyzer:
    def __init__(self, connection_string):
        """
        Inicializa o analisador com conex√£o ao MongoDB
        """
        try:
            if '@' in connection_string and 'mongodb+srv://' in connection_string:
                self.client = pymongo.MongoClient(connection_string)
            else:
                self.client = pymongo.MongoClient(connection_string)

            # Testar conex√£o
            self.client.admin.command('ping')
            print("‚úÖ Conectado ao MongoDB com sucesso!")

            self.db = self.client["mindcheck_analysis"]
            self.sia = SentimentIntensityAnalyzer()

        except Exception as e:
            print(f"‚ùå Erro de conex√£o com MongoDB: {e}")
            raise

    def load_and_clean_data(self, file_path):
        """
        Carrega e limpa os dados do arquivo JSON - VERS√ÉO CORRIGIDA
        """
        try:
            print(f"üìñ Lendo arquivo JSON: {file_path}")

            # Verificar se o arquivo existe
            if not os.path.exists(file_path):
                print(f"‚ùå Arquivo n√£o encontrado: {file_path}")
                return pd.DataFrame(), pd.DataFrame()

            # Ler arquivo JSON
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            print("üîç Analisando estrutura do JSON...")

            responses_df = pd.DataFrame()
            physio_df = pd.DataFrame()

            if 'responses' in data and 'physio' in data:
                print("‚úÖ Estrutura com arrays separados detectada")
                responses_df = pd.DataFrame(data['responses'])
                physio_df = pd.DataFrame(data['physio'])

                # Renomear colunas para o formato esperado
                if 'id' in physio_df.columns:
                    physio_df = physio_df.rename(columns={'id': 'phys_id'})

            # JSON com objetos no n√≠vel raiz
            elif isinstance(data, list):
                print("‚úÖ Estrutura de array √∫nico detectada")
                full_df = pd.DataFrame(data)

                # Verificar quais colunas existem
                response_columns = ['resp_id', 'timestamp', 'question', 'emoji', 'text', 'sentiment', 'mood_score']
                physio_columns = ['phys_id', 'id', 'timestamp', 'source', 'heart_rate', 'hrv', 'sleep_hours', 'steps',
                                  'stress_index']

                # Separar dados baseado nas colunas dispon√≠veis
                if any(col in full_df.columns for col in response_columns):
                    available_cols = [col for col in response_columns if col in full_df.columns]
                    responses_df = full_df[available_cols].copy()
                    responses_df = responses_df.dropna(subset=available_cols[:2], how='all')
                    print(f"üìù Encontradas {len(responses_df)} respostas")

                if any(col in full_df.columns for col in physio_columns):
                    available_cols = [col for col in physio_columns if col in full_df.columns]
                    physio_df = full_df[available_cols].copy()
                    physio_df = physio_df.dropna(subset=available_cols[:2], how='all')
                    print(f"üíì Encontrados {len(physio_df)} registros fisiol√≥gicos")

            #JSON com objetos aninhados
            elif isinstance(data, dict) and any(
                    key in data for key in ['responses', 'emotional_data', 'user_responses']):
                print("‚úÖ Estrutura com objetos aninhados detectada")
                # Tentar encontrar a chave correta para respostas
                for key in ['responses', 'emotional_data', 'user_responses']:
                    if key in data and isinstance(data[key], list):
                        responses_df = pd.DataFrame(data[key])
                        break

                # Tentar encontrar a chave correta para dados fisiol√≥gicos
                for key in ['physio', 'physio_samples', 'physiological_data', 'health_data']:
                    if key in data and isinstance(data[key], list):
                        physio_df = pd.DataFrame(data[key])
                        # Renomear coluna id para phys_id se necess√°rio
                        if 'id' in physio_df.columns and key == 'physio':
                            physio_df = physio_df.rename(columns={'id': 'phys_id'})
                        break

            else:
                print("‚ùå Estrutura JSON n√£o reconhecida")
                return pd.DataFrame(), pd.DataFrame()

            # Limpeza dos dados de respostas
            if not responses_df.empty:
                try:
                    responses_df['timestamp'] = pd.to_datetime(responses_df['timestamp'], errors='coerce')
                    responses_df = responses_df.dropna(subset=['timestamp'])

                    # Verificar se resp_id existe antes de remover duplicatas
                    if 'resp_id' in responses_df.columns:
                        responses_df = responses_df.drop_duplicates(subset=['resp_id'], keep='first')

                    print(f"‚úÖ {len(responses_df)} respostas v√°lidas ap√≥s limpeza")

                    # Mostrar preview dos dados
                    print(f"üìä Preview dos dados carregados:")
                    if 'emoji' in responses_df.columns:
                        print(f"   - Emojis encontrados: {responses_df['emoji'].unique()}")
                    if 'text' in responses_df.columns:
                        print(f"   - Textos: {responses_df['text'].tolist()[:3]}...")  # Mostrar apenas os 3 primeiros
                    if 'mood_score' in responses_df.columns:
                        print(f"   - Mood scores: {responses_df['mood_score'].tolist()}")

                except Exception as e:
                    print(f"‚ùå Erro na limpeza de respostas: {e}")
                    traceback.print_exc()
            else:
                print("‚ö†Ô∏è  Nenhuma resposta encontrada")

            # Limpeza dos dados fisiol√≥gicos
            if not physio_df.empty:
                try:
                    physio_df['timestamp'] = pd.to_datetime(physio_df['timestamp'], errors='coerce')
                    physio_df = physio_df.dropna(subset=['timestamp'])

                    # Verificar se phys_id existe antes de remover duplicatas
                    if 'phys_id' in physio_df.columns:
                        physio_df = physio_df.drop_duplicates(subset=['phys_id'], keep='first')
                    elif 'id' in physio_df.columns:
                        # Renomear id para phys_id
                        physio_df = physio_df.rename(columns={'id': 'phys_id'})
                        physio_df = physio_df.drop_duplicates(subset=['phys_id'], keep='first')

                    print(f"‚úÖ {len(physio_df)} registros fisiol√≥gicos v√°lidos ap√≥s limpeza")

                    # Mostrar preview dos dados fisiol√≥gicos
                    print(f"üìä Preview dos dados fisiol√≥gicos:")
                    if 'heart_rate' in physio_df.columns:
                        print(f"   - Frequ√™ncia card√≠aca: {physio_df['heart_rate'].tolist()}")
                    if 'sleep_hours' in physio_df.columns:
                        print(f"   - Horas de sono: {physio_df['sleep_hours'].tolist()}")
                    if 'steps' in physio_df.columns:
                        print(f"   - Passos: {physio_df['steps'].tolist()}")

                except Exception as e:
                    print(f"‚ùå Erro na limpeza de dados fisiol√≥gicos: {e}")
            else:
                print("‚ö†Ô∏è  Nenhum registro fisiol√≥gico encontrado - criando dados compat√≠veis...")
                # Criar dados fisiol√≥gicos compat√≠veis com as respostas
                physio_df = self._create_compatible_physio_data(responses_df)

            return responses_df, physio_df

        except json.JSONDecodeError as e:
            print(f"‚ùå Erro ao decodificar JSON: {e}")
            return pd.DataFrame(), pd.DataFrame()
        except Exception as e:
            print(f"‚ùå Erro ao carregar dados: {e}")
            traceback.print_exc()
            return pd.DataFrame(), pd.DataFrame()

    def _create_compatible_physio_data(self, responses_df):
        """
        Cria dados fisiol√≥gicos compat√≠veis com as respostas emocionais
        """
        if responses_df.empty:
            return pd.DataFrame()

        physio_data = []

        # Criar dados fisiol√≥gicos que fa√ßam sentido com os humores
        for i, response in responses_df.iterrows():
            mood_score = response.get('mood_score', 0)
            sentiment = response.get('sentiment', 0.5)
            timestamp = response['timestamp']

            # Gerar dados fisiol√≥gicos baseados no humor
            if mood_score == 1:  # Humor positivo
                heart_rate = np.random.randint(65, 75)  # FC baixa (relaxado)
                stress_index = round(np.random.uniform(0.1, 0.3), 2)  # Baixo estresse
                sleep_hours = round(np.random.uniform(7.5, 9.0), 1)  # Bom sono
                steps = np.random.randint(8000, 12000)  # Boa atividade

            elif mood_score == -1:  # Humor negativo
                heart_rate = np.random.randint(80, 95)  # FC alta (estressado)
                stress_index = round(np.random.uniform(0.5, 0.8), 2)  # Alto estresse
                sleep_hours = round(np.random.uniform(5.0, 6.5), 1)  # Sono ruim
                steps = np.random.randint(3000, 7000)  # Baixa atividade

            else:  # Humor neutro
                heart_rate = np.random.randint(70, 85)  # FC normal
                stress_index = round(np.random.uniform(0.3, 0.5), 2)  # Estresse m√©dio
                sleep_hours = round(np.random.uniform(6.5, 7.5), 1)  # Sono m√©dio
                steps = np.random.randint(6000, 9000)  # Atividade m√©dia

            # HRV varia inversamente com o estresse
            hrv = round(60 - (stress_index * 40) + np.random.uniform(-5, 5), 2)

            physio_record = {
                'phys_id': f'phys_{response.get("resp_id", f"sample_{i}")}',
                'timestamp': timestamp,
                'source': 'fitbit',
                'heart_rate': heart_rate,
                'hrv': hrv,
                'sleep_hours': sleep_hours,
                'steps': steps,
                'stress_index': stress_index
            }

            physio_data.append(physio_record)

        physio_df = pd.DataFrame(physio_data)
        print(f"‚úÖ Criados {len(physio_df)} registros fisiol√≥gicos compat√≠veis")
        return physio_df

    def create_sample_data(self):
        """
        Cria dados de exemplo se n√£o houver dados suficientes
        """
        print("üìã Criando dados de exemplo para demonstra√ß√£o...")

        # Dados de exemplo para respostas
        sample_responses = [
            {
                'resp_id': 'sample_1',
                'timestamp': datetime.now(),
                'question': 'check',
                'emoji': 'üòä',
                'text': 'Me sinto muito bem hoje',
                'sentiment': 0.9,
                'mood_score': 1
            },
            {
                'resp_id': 'sample_2',
                'timestamp': datetime.now(),
                'question': 'check',
                'emoji': 'üòê',
                'text': 'Estou mais ou menos',
                'sentiment': 0.5,
                'mood_score': 0
            },
            {
                'resp_id': 'sample_3',
                'timestamp': datetime.now(),
                'question': 'check',
                'emoji': 'üòî',
                'text': 'N√£o estou bem hoje',
                'sentiment': 0.2,
                'mood_score': -1
            }
        ]

        # Dados de exemplo fisiol√≥gicos
        sample_physio = [
            {
                'phys_id': 'phys_1',
                'timestamp': datetime.now(),
                'source': 'fitbit',
                'heart_rate': 72,
                'hrv': 45.5,
                'sleep_hours': 7.5,
                'steps': 8542,
                'stress_index': 0.3
            },
            {
                'phys_id': 'phys_2',
                'timestamp': datetime.now(),
                'source': 'fitbit',
                'heart_rate': 85,
                'hrv': 38.2,
                'sleep_hours': 6.2,
                'steps': 12345,
                'stress_index': 0.6
            }
        ]

        try:
            # Inserir dados de exemplo
            self.db.responses.insert_many(sample_responses)
            self.db.physio_data.insert_many(sample_physio)
            print("‚úÖ Dados de exemplo criados com sucesso!")
        except Exception as e:
            print(f"‚ùå Erro ao criar dados de exemplo: {e}")

    def upload_to_mongodb(self, responses_df, physio_df):
        """
        Faz upload dos dados para o MongoDB
        """
        try:
            # Verificar se h√° dados para upload
            if responses_df.empty and physio_df.empty:
                print("‚ö†Ô∏è  Nenhum dado para upload, criando dados de exemplo...")
                self.create_sample_data()
                return

            # Limpar cole√ß√µes existentes
            self.db.responses.delete_many({})
            self.db.physio_data.delete_many({})

            # Inserir respostas
            if not responses_df.empty:
                responses_records = responses_df.to_dict('records')
                result_responses = self.db.responses.insert_many(responses_records)
                print(f"‚úÖ {len(result_responses.inserted_ids)} respostas inseridas")

                # Mostrar estat√≠sticas das respostas
                if 'mood_score' in responses_df.columns:
                    mood_counts = responses_df['mood_score'].value_counts()
                    print(f"üìä Distribui√ß√£o de humor: {mood_counts.to_dict()}")

            else:
                print("‚è≠Ô∏è  Nenhuma resposta para inserir")

            # Inserir dados fisiol√≥gicos
            if not physio_df.empty:
                physio_records = physio_df.to_dict('records')
                result_physio = self.db.physio_data.insert_many(physio_records)
                print(f"‚úÖ {len(result_physio.inserted_ids)} registros fisiol√≥gicos inseridos")

                # Mostrar estat√≠sticas fisiol√≥gicas
                if 'heart_rate' in physio_df.columns:
                    avg_hr = physio_df['heart_rate'].mean()
                    print(f"üìä M√©dia FC: {avg_hr:.1f} bpm")
                if 'sleep_hours' in physio_df.columns:
                    avg_sleep = physio_df['sleep_hours'].mean()
                    print(f"üìä M√©dia sono: {avg_sleep:.1f} h")

            else:
                print("‚è≠Ô∏è  Nenhum registro fisiol√≥gico para inserir")

        except Exception as e:
            print(f"‚ùå Erro no upload para MongoDB: {e}")

    def text_mining_analysis(self):
        """
        Realiza an√°lise de minera√ß√£o de textos nas respostas emocionais
        """
        try:
            responses = list(self.db.responses.find())

            if not responses:
                print("‚ö†Ô∏è  Nenhuma resposta para an√°lise de texto")
                return

            print(f"üîç Analisando {len(responses)} textos...")

            for response in responses:
                text = response.get('text', '')

                if not text or not isinstance(text, str):
                    continue

                # An√°lise de Sentimento com VADER
                sentiment_scores = self.sia.polarity_scores(text)

                # An√°lise com TextBlob
                try:
                    blob = TextBlob(text)
                    polarity = blob.sentiment.polarity
                    subjectivity = blob.sentiment.subjectivity
                except:
                    polarity = 0.0
                    subjectivity = 0.0

                # Extra√ß√£o de palavras-chave
                words = text.lower().split()
                keywords = [word for word in words if len(word) > 2]

                # Atualizar documento com an√°lises
                self.db.responses.update_one(
                    {'_id': response['_id']},
                    {'$set': {
                        'vader_sentiment': sentiment_scores,
                        'textblob_polarity': polarity,
                        'textblob_subjectivity': subjectivity,
                        'keywords': keywords,
                        'text_length': len(text),
                        'word_count': len(words)
                    }}
                )

            print("‚úÖ An√°lise de minera√ß√£o de textos conclu√≠da")

        except Exception as e:
            print(f"‚ùå Erro na an√°lise de textos: {e}")

    def descriptive_statistics(self):
        """
        Calcula estat√≠sticas descritivas dos dados
        """
        try:
            # Estat√≠sticas das respostas emocionais
            responses = list(self.db.responses.find())
            if responses:
                mood_scores = [r.get('mood_score', 0) for r in responses]
                sentiments = [r.get('sentiment', 0.5) for r in responses]

                mood_stats = {
                    'mean': np.mean(mood_scores) if mood_scores else 0,
                    'median': np.median(mood_scores) if mood_scores else 0,
                    'std': np.std(mood_scores) if mood_scores else 0,
                    'min': np.min(mood_scores) if mood_scores else 0,
                    'max': np.max(mood_scores) if mood_scores else 0,
                    'count': len(mood_scores)
                }

                sentiment_stats = {
                    'mean': np.mean(sentiments) if sentiments else 0,
                    'median': np.median(sentiments) if sentiments else 0,
                    'std': np.std(sentiments) if sentiments else 0
                }
            else:
                mood_stats = {}
                sentiment_stats = {}

            # Estat√≠sticas dos dados fisiol√≥gicos
            physio_data = list(self.db.physio_data.find())
            if physio_data:
                heart_rates = [p.get('heart_rate', 0) for p in physio_data]
                sleep_hours = [p.get('sleep_hours', 0) for p in physio_data]
                stress_indices = [p.get('stress_index', 0) for p in physio_data]
                steps = [p.get('steps', 0) for p in physio_data]

                hr_stats = {
                    'mean': np.mean(heart_rates) if heart_rates else 0,
                    'median': np.median(heart_rates) if heart_rates else 0,
                    'std': np.std(heart_rates) if heart_rates else 0,
                    'min': np.min(heart_rates) if heart_rates else 0,
                    'max': np.max(heart_rates) if heart_rates else 0
                }

                sleep_stats = {
                    'mean': np.mean(sleep_hours) if sleep_hours else 0,
                    'median': np.median(sleep_hours) if sleep_hours else 0,
                    'std': np.std(sleep_hours) if sleep_hours else 0
                }

                steps_stats = {
                    'mean': np.mean(steps) if steps else 0,
                    'median': np.median(steps) if steps else 0,
                    'std': np.std(steps) if steps else 0
                }
            else:
                hr_stats = {}
                sleep_stats = {}
                steps_stats = {}

            return {
                'mood_statistics': mood_stats,
                'sentiment_statistics': sentiment_stats,
                'heart_rate_statistics': hr_stats,
                'sleep_statistics': sleep_stats,
                'steps_statistics': steps_stats
            }

        except Exception as e:
            print(f"‚ùå Erro no c√°lculo de estat√≠sticas: {e}")
            return {}

    def correlation_analysis(self):
        """
        Realiza an√°lise de correla√ß√£o entre dados emocionais e fisiol√≥gicos
        """
        try:
            correlations = []
            responses = list(self.db.responses.find())

            for response in responses:
                response_time = response.get('timestamp')
                if not response_time:
                    continue

                # Encontrar dados fisiol√≥gicos mais pr√≥ximos no tempo
                nearest_physio = self.db.physio_data.find_one({
                    'timestamp': {
                        '$gte': response_time - pd.Timedelta(minutes=60),
                        '$lte': response_time + pd.Timedelta(minutes=60)
                    }
                })

                if nearest_physio:
                    correlation_data = {
                        'mood_score': response.get('mood_score', 0),
                        'sentiment': response.get('sentiment', 0.5),
                        'textblob_polarity': response.get('textblob_polarity', 0),
                        'heart_rate': nearest_physio.get('heart_rate', 0),
                        'hrv': nearest_physio.get('hrv', 0),
                        'sleep_hours': nearest_physio.get('sleep_hours', 0),
                        'steps': nearest_physio.get('steps', 0),
                        'stress_index': nearest_physio.get('stress_index', 0),
                        'timestamp': response_time
                    }
                    correlations.append(correlation_data)

            # Calcular correla√ß√µes se houver dados suficientes
            if len(correlations) > 1:
                corr_df = pd.DataFrame(correlations)
                # Selecionar apenas colunas num√©ricas
                numeric_df = corr_df.select_dtypes(include=[np.number])

                if not numeric_df.empty:
                    correlation_matrix = numeric_df.corr()

                    results = {
                        'correlation_matrix': correlation_matrix.to_dict(),
                        'pairs_analyzed': len(correlations)
                    }

                    # Adicionar correla√ß√µes espec√≠ficas se existirem
                    if 'mood_score' in correlation_matrix.index:
                        for col in ['heart_rate', 'sleep_hours', 'stress_index', 'steps']:
                            if col in correlation_matrix.columns:
                                results[f'mood_{col}_corr'] = correlation_matrix.loc['mood_score', col]

                    return results

            return {
                'error': 'Dados insuficientes para an√°lise de correla√ß√£o',
                'pairs_analyzed': len(correlations)
            }

        except Exception as e:
            print(f"‚ùå Erro na an√°lise de correla√ß√£o: {e}")
            return {'error': str(e)}

    def generate_insights(self, stats, correlations):
        """
        Gera insights baseados nas an√°lises realizadas
        """
        insights = []

        try:
            # Insights baseados em correla√ß√£o
            if 'mood_heart_rate_corr' in correlations:
                mood_hr_corr = correlations['mood_heart_rate_corr']
                if abs(mood_hr_corr) > 0.7:
                    insights.append(f"Correla√ß√£o muito forte entre humor e frequ√™ncia card√≠aca: {mood_hr_corr:.3f}")
                elif abs(mood_hr_corr) > 0.5:
                    insights.append(f"Correla√ß√£o moderada entre humor e frequ√™ncia card√≠aca: {mood_hr_corr:.3f}")

            if 'mood_sleep_corr' in correlations:
                mood_sleep_corr = correlations['mood_sleep_corr']
                if abs(mood_sleep_corr) > 0.6:
                    insights.append(f"Correla√ß√£o entre humor e horas de sono: {mood_sleep_corr:.3f}")

            # Insights baseados em estat√≠sticas
            if 'mood_statistics' in stats and stats['mood_statistics']:
                avg_mood = stats['mood_statistics'].get('mean', 0)
                if avg_mood < -0.5:
                    insights.append("Humor m√©dio dos usu√°rios est√° significativamente negativo")
                elif avg_mood < 0:
                    insights.append("Tend√™ncia de humor levemente negativo")
                elif avg_mood > 0.5:
                    insights.append("Humor m√©dio dos usu√°rios est√° positivo")

            if 'heart_rate_statistics' in stats and stats['heart_rate_statistics']:
                avg_hr = stats['heart_rate_statistics'].get('mean', 0)
                if avg_hr > 90:
                    insights.append("Frequ√™ncia card√≠aca m√©dia elevada - poss√≠vel indicador de estresse")
                elif avg_hr < 60:
                    insights.append("Frequ√™ncia card√≠aca m√©dia baixa - poss√≠vel estado de relaxamento")

            # Insight sobre quantidade de dados
            if 'pairs_analyzed' in correlations:
                pairs = correlations['pairs_analyzed']
                if pairs < 3:
                    insights.append(f"Poucos dados para an√°lise: apenas {pairs} pares de dados")
                else:
                    insights.append(f"An√°lise baseada em {pairs} pares de dados")

        except Exception as e:
            print(f"Erro ao gerar insights: {e}")

        return insights if insights else ["Coletando mais dados para insights detalhados"]

    def process_complete_analysis(self, json_file_path):
        """
        Processa a an√°lise completa dos dados a partir de JSON
        """
        print("=" * 50)
        print("INICIANDO AN√ÅLISE MINCHECK (JSON)")
        print("=" * 50)

        print("1. üìÇ Carregando e limpando dados do JSON...")
        responses_df, physio_df = self.load_and_clean_data(json_file_path)

        print("2. üóÑÔ∏è Upload para MongoDB...")
        self.upload_to_mongodb(responses_df, physio_df)

        print("3. üìù An√°lise de minera√ß√£o de textos...")
        self.text_mining_analysis()

        print("4. üìä Estat√≠sticas descritivas...")
        stats = self.descriptive_statistics()

        print("5. üîó An√°lise de correla√ß√£o...")
        correlations = self.correlation_analysis()

        print("6. üí° Gerando insights...")
        insights = self.generate_insights(stats, correlations)

        print("7. ‚úÖ An√°lise conclu√≠da!")
        print("=" * 50)

        return {
            'statistics': stats,
            'correlations': correlations,
            'insights': insights
        }

    def print_results(self, results):
        """
        Imprime os resultados de forma organizada
        """
        print("\n" + "=" * 60)
        print("RESULTADOS DA AN√ÅLISE")
        print("=" * 60)

        # Estat√≠sticas
        if 'statistics' in results:
            stats = results['statistics']
            print("\nESTAT√çSTICAS DESCRITIVAS:")
            for category, values in stats.items():
                if values:  # S√≥ mostrar se n√£o estiver vazio
                    print(f"\n{category.upper().replace('_', ' ')}:")
                    for key, value in values.items():
                        if isinstance(value, (int, float)):
                            print(f"  {key}: {value:.2f}")
                        else:
                            print(f"  {key}: {value}")

        # Correla√ß√µes
        if 'correlations' in results:
            corr = results['correlations']
            print("\nCORRELA√á√ïES:")
            for key, value in corr.items():
                if key not in ['correlation_matrix', 'pairs_analyzed', 'error']:
                    if isinstance(value, (int, float)):
                        print(f"  {key}: {value:.3f}")
                    else:
                        print(f"  {key}: {value}")
            if 'pairs_analyzed' in corr:
                print(f"  Pares analisados: {corr['pairs_analyzed']}")

        # Insights
        if 'insights' in results:
            print("\nINSIGHTS:")
            for insight in results['insights']:
                print(f"  ‚Ä¢ {insight}")


class MindCheckVisualizer:
    def __init__(self, analyzer):
        self.analyzer = analyzer
        self.setup_style()

    def setup_style(self):
        """Configura o estilo dos gr√°ficos"""
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['axes.unicode_minus'] = False
        sns.set_palette("husl")

        self.colors = {
            'primary': '#2E86AB',
            'secondary': '#A23B72',
            'success': '#18A999',
            'warning': '#F18F01',
            'danger': '#C73E1D'
        }

    def create_executive_summary(self, results):
        """
        Cria um resumo executivo
        """
        print("\n" + "=" * 60)
        print("RESUMO EXECUTIVO - MINDCHECK")
        print("=" * 60)

        stats = results.get('statistics', {})
        correlations = results.get('correlations', {})
        insights = results.get('insights', [])

        # Cards de m√©tricas principais
        fig, axes = plt.subplots(2, 3, figsize=(18, 10))
        fig.suptitle('Resumo Executivo - M√©tricas Principais', fontsize=20, fontweight='bold')

        # M√©trica 1: Humor M√©dio
        mood_stats = stats.get('mood_statistics', {})
        avg_mood = mood_stats.get('mean', 0)
        axes[0, 0].text(0.5, 0.5, f'{avg_mood:.2f}', ha='center', va='center', fontsize=40,
                        color='green' if avg_mood > 0 else 'red' if avg_mood < 0 else 'gray')
        axes[0, 0].set_title('Humor Medio', fontsize=14, fontweight='bold')
        axes[0, 0].axis('off')

        # M√©trica 2: Frequ√™ncia Card√≠aca M√©dia
        hr_stats = stats.get('heart_rate_statistics', {})
        avg_hr = hr_stats.get('mean', 0)
        axes[0, 1].text(0.5, 0.5, f'{avg_hr:.0f} bpm', ha='center', va='center', fontsize=40,
                        color='red' if avg_hr > 85 else 'green')
        axes[0, 1].set_title('FC Media', fontsize=14, fontweight='bold')
        axes[0, 1].axis('off')

        # M√©trica 3: Horas de Sono
        sleep_stats = stats.get('sleep_statistics', {})
        avg_sleep = sleep_stats.get('mean', 0)
        axes[0, 2].text(0.5, 0.5, f'{avg_sleep:.1f}h', ha='center', va='center', fontsize=40,
                        color='green' if avg_sleep >= 7 else 'orange')
        axes[0, 2].set_title('Sono Medio', fontsize=14, fontweight='bold')
        axes[0, 2].axis('off')

        # M√©trica 4: Correla√ß√£o Humor-FC
        mood_hr_corr = correlations.get('mood_heart_rate_corr', 0)
        axes[1, 0].text(0.5, 0.5, f'{mood_hr_corr:.3f}', ha='center', va='center', fontsize=40,
                        color='blue' if abs(mood_hr_corr) > 0.5 else 'gray')
        axes[1, 0].set_title('Correlacao Humor-FC', fontsize=14, fontweight='bold')
        axes[1, 0].axis('off')

        # M√©trica 5: Total de Respostas
        total_responses = mood_stats.get('count', 0)
        axes[1, 1].text(0.5, 0.5, f'{total_responses}', ha='center', va='center', fontsize=40,
                        color='purple')
        axes[1, 1].set_title('Total Respostas', fontsize=14, fontweight='bold')
        axes[1, 1].axis('off')

        # M√©trica 6: Status
        status = "Dados OK" if total_responses > 0 else "Aguardando dados"
        axes[1, 2].text(0.5, 0.5, status, ha='center', va='center', fontsize=20,
                        color='green' if total_responses > 0 else 'orange')
        axes[1, 2].set_title('Status', fontsize=14, fontweight='bold')
        axes[1, 2].axis('off')

        plt.tight_layout()
        plt.show()

        # Listar todos os insights
        print("\nPRINCIPAIS INSIGHTS:")
        for i, insight in enumerate(insights, 1):
            print(f"   {i}. {insight}")

    def create_complete_dashboard(self, results):
        """
        Cria dashboard completo com visualiza√ß√µes b√°sicas
        """
        print("\nGERANDO DASHBOARD VISUAL...")

        try:
            # Verificar se h√° dados
            responses_count = self.analyzer.db.responses.count_documents({})
            physio_count = self.analyzer.db.physio_data.count_documents({})

            if responses_count == 0 and physio_count == 0:
                print("‚ö†Ô∏è  Nenhum dado dispon√≠vel para visualiza√ß√µes")
                return

            # Criar visualiza√ß√µes b√°sicas
            if responses_count > 0:
                self.create_mood_analysis()
                self.create_word_cloud()

            if physio_count > 0:
                self.create_physiological_insights()

            if responses_count > 0 and physio_count > 0:
                self.create_correlation_analysis(results)

            print("‚úÖ Dashboard gerado com sucesso!")

        except Exception as e:
            print(f"‚ùå Erro ao gerar dashboard: {e}")

    def create_mood_analysis(self):
        """Cria an√°lise de humor b√°sica"""
        try:
            responses = list(self.analyzer.db.responses.find())
            if not responses:
                print("‚ö†Ô∏è  Nenhuma resposta para an√°lise de humor")
                return

            fig, axes = plt.subplots(1, 2, figsize=(15, 6))
            fig.suptitle('An√°lise de Humor dos Usu√°rios', fontsize=16)

            # Distribui√ß√£o do humor
            mood_scores = [r.get('mood_score', 0) for r in responses]
            axes[0].hist(mood_scores, bins=5, color=self.colors['primary'], alpha=0.7)
            axes[0].set_xlabel('Pontua√ß√£o de Humor')
            axes[0].set_ylabel('Frequ√™ncia')
            axes[0].set_title('Distribui√ß√£o do Humor')
            axes[0].grid(True, alpha=0.3)

            # An√°lise de sentimentos
            sentiments = [r.get('sentiment', 0.5) for r in responses]
            axes[1].hist(sentiments, bins=10, color=self.colors['secondary'], alpha=0.7)
            axes[1].set_xlabel('Sentimento')
            axes[1].set_ylabel('Frequ√™ncia')
            axes[1].set_title('Distribui√ß√£o de Sentimentos')
            axes[1].grid(True, alpha=0.3)

            plt.tight_layout()
            plt.show()

        except Exception as e:
            print(f"‚ùå Erro na an√°lise de humor: {e}")

    def create_physiological_insights(self):
        """Cria insights fisiol√≥gicos b√°sicos"""
        try:
            physio_data = list(self.analyzer.db.physio_data.find())
            if not physio_data:
                print("‚ö†Ô∏è  Nenhum dado fisiol√≥gico para an√°lise")
                return

            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle('An√°lise de Dados Fisiol√≥gicos', fontsize=16)

            # Frequ√™ncia card√≠aca
            heart_rates = [p.get('heart_rate', 0) for p in physio_data]
            axes[0, 0].hist(heart_rates, bins=10, color=self.colors['primary'], alpha=0.7)
            axes[0, 0].set_title('Distribui√ß√£o da Frequ√™ncia Card√≠aca')
            axes[0, 0].set_xlabel('Frequ√™ncia Card√≠aca (bpm)')
            axes[0, 0].grid(True, alpha=0.3)

            # Horas de sono
            sleep_hours = [p.get('sleep_hours', 0) for p in physio_data]
            axes[0, 1].hist(sleep_hours, bins=8, color=self.colors['success'], alpha=0.7)
            axes[0, 1].set_title('Distribui√ß√£o de Horas de Sono')
            axes[0, 1].set_xlabel('Horas de Sono')
            axes[0, 1].grid(True, alpha=0.3)

            # Passos
            steps = [p.get('steps', 0) for p in physio_data]
            axes[1, 0].hist(steps, bins=10, color=self.colors['warning'], alpha=0.7)
            axes[1, 0].set_title('Distribui√ß√£o de Passos')
            axes[1, 0].set_xlabel('Passos')
            axes[1, 0].grid(True, alpha=0.3)

            # Estresse
            stress_indices = [p.get('stress_index', 0) for p in physio_data]
            axes[1, 1].hist(stress_indices, bins=10, color=self.colors['danger'], alpha=0.7)
            axes[1, 1].set_title('Distribui√ß√£o do √çndice de Estresse')
            axes[1, 1].set_xlabel('√çndice de Estresse')
            axes[1, 1].grid(True, alpha=0.3)

            plt.tight_layout()
            plt.show()

        except Exception as e:
            print(f"‚ùå Erro nos insights fisiol√≥gicos: {e}")

    def create_correlation_analysis(self, results):
        """Cria an√°lise de correla√ß√£o b√°sica"""
        try:
            # Usar dados das correla√ß√µes j√° calculadas
            correlations = results.get('correlations', {})

            if 'error' in correlations:
                print(f"‚ö†Ô∏è  {correlations['error']}")
                return

            # Criar heatmap simples se tiver matriz de correla√ß√£o
            if 'correlation_matrix' in correlations:
                corr_matrix = correlations['correlation_matrix']
                if corr_matrix:
                    # Converter para DataFrame
                    corr_df = pd.DataFrame(corr_matrix)

                    plt.figure(figsize=(10, 8))
                    sns.heatmap(corr_df, annot=True, cmap='coolwarm', center=0,
                                square=True, linewidths=0.5)
                    plt.title('Mapa de Correla√ß√£o entre M√©tricas')
                    plt.tight_layout()
                    plt.show()

        except Exception as e:
            print(f"‚ùå Erro na an√°lise de correla√ß√£o: {e}")

    def create_word_cloud(self):
        """Cria nuvem de palavras"""
        try:
            responses = list(self.analyzer.db.responses.find())
            texts = [response.get('text', '') for response in responses if response.get('text')]

            if not texts:
                print("‚ö†Ô∏è  Nenhum texto dispon√≠vel para nuvem de palavras")
                return

            all_text = ' '.join(texts)

            wordcloud = WordCloud(
                width=800,
                height=400,
                background_color='white',
                colormap='viridis',
                max_words=50
            ).generate(all_text)

            plt.figure(figsize=(12, 6))
            plt.imshow(wordcloud, interpolation='bilinear')
            plt.axis('off')
            plt.title('Palavras Mais Frequentes nas Respostas Emocionais', fontsize=16)
            plt.tight_layout()
            plt.show()

        except Exception as e:
            print(f"‚ùå Erro ao criar nuvem de palavras: {e}")


def main():
    CONNECTION_STRING = "mongodb+srv://persi:persi@projetopersi.iypaiqd.mongodb.net/?appName=ProjetoPersi"
    JSON_FILE_PATH = r"C:\Users\Pichau\Desktop\Projetos Python\FIAP\Bagagem\mindcheck_export_ea366a.json"  # Mude para .json

    try:
        print("üîß Inicializando analisador...")
        analyzer = MindCheckAnalyzer(CONNECTION_STRING)

        print("üìÅ Verificando arquivo JSON...")
        if not os.path.exists(JSON_FILE_PATH):
            print(f"‚ùå Arquivo JSON n√£o encontrado: {JSON_FILE_PATH}")
            print("üí° Criando dados de exemplo...")
            analyzer.create_sample_data()
            results = {
                'statistics': {},
                'correlations': {'error': 'Usando dados de exemplo'},
                'insights': ['Analisando dados de exemplo demonstrativos']
            }
        else:
            print("üöÄ Executando an√°lise completa a partir do JSON...")
            results = analyzer.process_complete_analysis(JSON_FILE_PATH)

        print("\nüé® GERANDO VISUALIZA√á√ïES...")
        visualizer = MindCheckVisualizer(analyzer)

        # Resumo executivo
        visualizer.create_executive_summary(results)

        # Dashboard completo
        visualizer.create_complete_dashboard(results)

        print("üìã Exibindo resultados...")
        analyzer.print_results(results)

    except Exception as e:
        print(f"‚ùå Erro durante a execu√ß√£o: {e}")
        traceback.print_exc()


if __name__ == "__main__":
    main()